{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from openai import OpenAI\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"http://sionic.chat:8001/v1\",\n",
    "    api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf\")\n",
    "pdf_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents.extend(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunk = chunk_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=chunk, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"안녕?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jhgan/ko-sbert-nli 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0, length_function=tiktoken_len)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name =\"jhgan/ko-sbert-nli\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# texts들에 대해 hf 임베딩 모델로 임베딩 하는 과정 -> 이를 docsearch에 저장\n",
    "docsearch = Chroma.from_documents(docs, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# llm = ChatOpenAI(base_url = \"http://sionic.chat:8001/v1\",\n",
    "#     api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\",\n",
    "#     model=\"xionic-ko-llama-3-70b\",\n",
    "#     temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = RetrievalQA.from_chain_type(llm = llm,\n",
    "#                                  chain_type= \"stuff\",\n",
    "#                                  retriever = docsearch.as_retriever(\n",
    "#                                      search_type=\"mmr\",\n",
    "#                                      search_kwargs={'k':3, 'fetch_k': 10}),\n",
    "#                                      return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"최저수당 대해 출력해줘\"\n",
    "result = qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '최저수당 대해 출력해줘',\n",
       " 'result': 'I apologize, but there is no mention of \"최저수당\" (minimum wage) in the provided context. The context appears to be related to labor laws and regulations, but it does not specifically mention minimum wage. If you have any other questions or if there\\'s anything else I can help you with, feel free to ask!',\n",
       " 'source_documents': [Document(metadata={'page': 7, 'source': 'C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf'}, page_content='임금을 보장하여야 한다.\\n \\n제48조(임금대장 및 임금명세서) ① 사용자는 각 사업장별로 임금대장을 작성하고 임금과 가족수당 계산의 기초가 되\\n는 사항, 임금액, 그 밖에 대통령령으로 정하는 사항을 임금을 지급할 때마다 적어야 한다. <개정 2021. 5. 18.>\\n② 사용자는 임금을 지급하는 때에는 근로자에게 임금의 구성항목ㆍ계산방법, 제43조제1항 단서에 따라 임금의 일\\n부를 공제한 경우의 내역 등 대통령령으로 정하는 사항을 적은 임금명세서를 서면(「전자문서 및 전자거래 기본법」\\n제2조제1호에 따른 전자문서를 포함한다)으로 교부하여야 한다.<신설 2021. 5. 18.>\\n[제목개정 2021. 5. 18.]\\n \\n제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\\n \\n       제4장 근로시간과 휴식\\n \\n제50조(근로시간) ① 1주 간의 근로시간은 휴게시간을 제외하고 40시간을 초과할 수 없다.\\n② 1일의 근로시간은 휴게시간을 제외하고 8시간을 초과할 수 없다.'),\n",
       "  Document(metadata={'page': 7, 'source': 'C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf'}, page_content='임금을 보장하여야 한다.\\n \\n제48조(임금대장 및 임금명세서) ① 사용자는 각 사업장별로 임금대장을 작성하고 임금과 가족수당 계산의 기초가 되\\n는 사항, 임금액, 그 밖에 대통령령으로 정하는 사항을 임금을 지급할 때마다 적어야 한다. <개정 2021. 5. 18.>\\n② 사용자는 임금을 지급하는 때에는 근로자에게 임금의 구성항목ㆍ계산방법, 제43조제1항 단서에 따라 임금의 일\\n부를 공제한 경우의 내역 등 대통령령으로 정하는 사항을 적은 임금명세서를 서면(「전자문서 및 전자거래 기본법」\\n제2조제1호에 따른 전자문서를 포함한다)으로 교부하여야 한다.<신설 2021. 5. 18.>\\n[제목개정 2021. 5. 18.]\\n \\n제49조(임금의 시효) 이 법에 따른 임금채권은 3년간 행사하지 아니하면 시효로 소멸한다.\\n \\n       제4장 근로시간과 휴식\\n \\n제50조(근로시간) ① 1주 간의 근로시간은 휴게시간을 제외하고 40시간을 초과할 수 없다.\\n② 1일의 근로시간은 휴게시간을 제외하고 8시간을 초과할 수 없다.'),\n",
       "  Document(metadata={'page': 7, 'source': 'C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf'}, page_content='법제처                                                            8                                                       국가법령정보센터\\n근로기준법 \\n[본조신설 2007. 7. 27.]\\n \\n제45조(비상시 지급) 사용자는 근로자가 출산, 질병, 재해, 그 밖에 대통령령으로 정하는 비상(非常)한 경우의 비용에 충\\n당하기 위하여 임금 지급을 청구하면 지급기일 전이라도 이미 제공한 근로에 대한 임금을 지급하여야 한다.\\n \\n제46조(휴업수당) ① 사용자의 귀책사유로 휴업하는 경우에 사용자는 휴업기간 동안 그 근로자에게 평균임금의 100분\\n의 70 이상의 수당을 지급하여야 한다. 다만, 평균임금의 100분의 70에 해당하는 금액이 통상임금을 초과하는 경우\\n에는 통상임금을 휴업수당으로 지급할 수 있다.\\n② 제1항에도 불구하고 부득이한 사유로 사업을 계속하는 것이 불가능하여 노동위원회의 승인을 받은 경우에는 제\\n1항의 기준에 못 미치는 휴업수당을 지급할 수 있다.\\n \\n제47조(도급 근로자) 사용자는 도급이나 그 밖에 이에 준하는 제도로 사용하는 근로자에게 근로시간에 따라 일정액의\\n임금을 보장하여야 한다.')]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url = \"http://sionic.chat:8001/v1\",\n",
    "    api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, result):\n",
    "    # 질문과 관련된 문서를 사용하여 RAG를 수행하는 요청\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"xionic-ko-llama-3-70b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant. You will be given a task. You must generate a detailed and long answer in korean.\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        result=result\n",
    "    )\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"최저수당이 뭐야?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generate_answer(question, result)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0, length_function=tiktoken_len)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name =\"jhgan/ko-sbert-nli\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# texts들에 대해 hf 임베딩 모델로 임베딩 하는 과정 -> 이를 docsearch에 저장\n",
    "docsearch = Chroma.from_documents(texts, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm = openai,\n",
    "                                 chain_type= \"stuff\",\n",
    "                                 retriever = docsearch.as_retriever(\n",
    "                                     search_type=\"mmr\",\n",
    "                                     search_kwargs={'k':3, 'fetch_k': 10}),\n",
    "                                     return_source_documents=True)\n",
    "\n",
    "query=\"1대1 대화하는 법에 대해 설명해줘\"\n",
    "result = qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query):\n",
    "    # 쿼리를 사용하여 문서 검색\n",
    "    results = db.similarity_search(query)\n",
    "    \n",
    "    # 검색 결과 중에서 첫 번째 문서의 내용을 반환\n",
    "    if results:\n",
    "        return results[0].page_content\n",
    "    else:\n",
    "        return \"검색 결과를 찾을 수 없습니다.\"\n",
    "\n",
    "# 가상의 챗봇 구현\n",
    "def chatbot(query):\n",
    "    # 사용자 질문을 받아서 문서 검색\n",
    "    answer = search_documents(query)\n",
    "    return answer\n",
    "\n",
    "# 사용자 입력 받기\n",
    "user_query = input(\"질문을 입력하세요: \")\n",
    "\n",
    "# 챗봇으로부터 답변 받기\n",
    "answer = chatbot(user_query)\n",
    "\n",
    "# 챗봇의 답변 출력\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(llm, template_path, output_key):\n",
    "    return LLMChain(\n",
    "        llm = llm,\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            template=read_prompt_template(template_path)\n",
    "        ),\n",
    "        output_key=output_key,\n",
    "        verbose=True,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(base_url = \"http://sionic.chat:8001/v1\",\n",
    "    api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\",\n",
    "    model=\"xionic-ko-llama-3-70b\",\n",
    "    temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = create_chain(\n",
    "    llm = llm,\n",
    "    template_path=docs,\n",
    "    output_key=\"text\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"안녕하세요?\", \"한국어 문장 임베딩을 위한 버트 모델입니다.\"]\n",
    "\n",
    "model = SentenceTransformer('jhgan/ko-sbert-nli')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "# split it into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0, length_function=tiktoken_len)\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name =\"jhgan/ko-sbert-nli\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "ko = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "db = FAISS.from_documents(docs, ko)\n",
    "\n",
    "query = \"근로의 정의를 알려줘\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 베이스라인 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "from langchain.chains import ConversationChain, LLMChain, LLMRouterChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "loader = PyPDFLoader(\"C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/test/labor_low.pdf\")\n",
    "pdf_documents = loader.load()\n",
    "documents.extend(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(llm, documents, output_key):\n",
    "    chains = []\n",
    "    for doc in documents:\n",
    "        prompt = doc.page_content  # 각 문서의 내용을 prompt로 사용\n",
    "        chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=prompt,\n",
    "            output_key=output_key,\n",
    "            verbose=True\n",
    "        )\n",
    "        chains.append(chain)\n",
    "    \n",
    "    return chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(base_url = \"http://sionic.chat:8001/v1\",\n",
    "    api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\",\n",
    "    model=\"xionic-ko-llama-3-70b\",\n",
    "    temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_2 = create_chain(\n",
    "    llm=llm,\n",
    "    documents=documents,\n",
    "    output_key=\"text\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
