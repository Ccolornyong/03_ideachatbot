{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUNJIN\\anaconda3\\envs\\intern\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain_core.prompt_values import ChatPromptValue\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import RetrievalQA\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from typing import Dict, List, Optional\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from typing import Dict, List, Optional\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.environ.get('Openai_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLSXLoader(BaseLoader):\n",
    "    \"\"\"Loads an XLSX file into a list of documents from specified sheets.\n",
    "\n",
    "    Each document represents one row of the XLSX file. Every row is converted into a\n",
    "    key/value pair and outputted to a new line in the document's page_content, including\n",
    "    the sheet name.\n",
    "\n",
    "    The source for each document loaded from xlsx is set to the value of the\n",
    "    'file_path' argument for all documents by default.\n",
    "    You can override this by setting the 'source_column' argument to the\n",
    "    name of a column in the XLSX file.\n",
    "    The source of each document will then be set to the value of the column\n",
    "    with the name specified in 'source_column'.\n",
    "\n",
    "    Output Example:\n",
    "        .. code-block:: txt\n",
    "\n",
    "            sheet: SheetName\n",
    "            column1: value1\n",
    "            column2: None\n",
    "            column3: value3\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            file_path: str,\n",
    "            source_column: Optional[str] = None,\n",
    "            encoding: Optional[str] = None,\n",
    "            exclude_columns: Optional[List[str]] = None,  # 열을 제외할 목록\n",
    "            target_sheets: Optional[List[str]] = None  # 불러올 시트 목록\n",
    "    ):\n",
    "        self.file_path = file_path\n",
    "        self.source_column = source_column\n",
    "        self.encoding = encoding\n",
    "        self.exclude_columns = exclude_columns if exclude_columns else []\n",
    "        self.target_sheets = target_sheets if target_sheets else []\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "\n",
    "        wb = load_workbook(filename=self.file_path, read_only=True, data_only=True)\n",
    "\n",
    "        # 특정 시트를 처리\n",
    "        sheets_to_process = self.target_sheets if self.target_sheets else wb.sheetnames[1:]\n",
    "\n",
    "        for sheet_name in sheets_to_process:\n",
    "            if sheet_name in wb.sheetnames:\n",
    "                ws = wb[sheet_name]\n",
    "                headers = [cell.value for cell in ws[1]]\n",
    "                headers = [header if header is not None else '' for header in headers]  # None을 빈 문자열로 변환\n",
    "\n",
    "                # 이전 행의 값을 저장하기 위한 리스트\n",
    "                previous_row = [None] * len(headers)\n",
    "\n",
    "                for i, row in enumerate(ws.iter_rows(min_row=2)):\n",
    "                    row_values = [cell.value for cell in row]\n",
    "\n",
    "                    # None 값을 이전 행의 값으로 대체, 제외할 열을 처리\n",
    "                    for j, (value, header) in enumerate(zip(row_values, headers)):\n",
    "                        if value is None and header not in self.exclude_columns:\n",
    "                            row_values[j] = previous_row[j]\n",
    "\n",
    "                        # '단종 여부' 열 처리\n",
    "                        if header == '단종 여부' and value is None:\n",
    "                            row_values[j] = '해당없음'\n",
    "\n",
    "                        # '구분' 열 처리\n",
    "                        if header == '구분':\n",
    "                            if value is None:\n",
    "                                row_values[j] = previous_row[j]\n",
    "                            if 'ODM' in (row_values[j] or ''):\n",
    "                                row_values[j] = 'ODM'\n",
    "                            else:\n",
    "                                row_values[j] = 'OEM'\n",
    "\n",
    "                    row_dict = dict(zip(headers, row_values))\n",
    "\n",
    "                    # 시트 이름과 None 값을 처리하여 'None' 문자열로 변환\n",
    "                    content_lines = [f\"sheet: {sheet_name}\"]  # 시트 이름 추가\n",
    "                    content_lines.extend(\n",
    "                        f\"{k.strip()}: {str(v) if v is not None else 'None'}\"\n",
    "                        for k, v in row_dict.items()\n",
    "                        if k.strip() != ''  # 빈 헤더 무시\n",
    "                    )\n",
    "                    content = \"\\n\".join(content_lines)\n",
    "\n",
    "                    if self.source_column is not None:\n",
    "                        source = row_dict.get(self.source_column, 'None')  # source_column이 없는 경우 'None' 사용\n",
    "                    else:\n",
    "                        source = self.file_path\n",
    "\n",
    "                    metadata = {\"source\": source, \"sheet\": sheet_name}\n",
    "                    doc = Document(page_content=content, metadata=metadata)\n",
    "                    docs.append(doc)\n",
    "\n",
    "                    # 현재 행의 값을 이전 행으로 저장\n",
    "                    previous_row = row_values\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "loader = XLSXLoader(\n",
    "    file_path=\"C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/data/년도별 신제품 리스트_냉장-240425.xlsx\",\n",
    "    source_column=\"제품명\",\n",
    "    exclude_columns=[\"단종 여부\"],  # 제외할 열 지정\n",
    "    target_sheets=[\"2023\"]  # 불러올 시트 지정\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이징\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10, length_function=tiktoken_len)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SUNJIN\\anaconda3\\envs\\intern\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\SUNJIN\\anaconda3\\envs\\intern\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 벡터화에 사용할 모델\n",
    "model_name =\"jhgan/ko-sbert-nli\"\n",
    "# model_kwargs = {'device': 'cuda'} # gpu 사용\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB에 넣고 리트리버 구성\n",
    "docsearch = Chroma.from_documents(texts, hf)\n",
    "retriever = docsearch.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
    "                    streaming=True, callbacks=[StreamingStdOutCallbackHandler()],\n",
    "                    temperature = 1,\n",
    "                    max_tokens = 300,\n",
    "                    api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "      \"당신은 회사 제품을 잘 알고 있는 마케딩 디렉터입니다.\"\n",
    "      \"답변은 사용자가 질문한 언어와 같은 언어를 사용하세요.\"\n",
    "      \"다음 질문에 대해 주어진 문맥을 사용하여 상세하고 정확한 답변을 제공해주세요. \"\n",
    "      \"관련 문맥 부분을 참조하여 답변을 작성하세요.\\n\\n\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    openai, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"\"\"\n",
    "    You MUST Answer in Korean.\n",
    "    당신은 회사 제품을 잘 알고 있는 신제품 개발 팀장입니다.\n",
    "    새로운 제품을 출시하기 위해 과거 신제품에 대한 정보를 모두 알고 있으며 팀원들이 특정 제품에 대해 물어볼 때 모두 대답할 수 있어야합니다.\n",
    "    물어본 특성에 해당하는 제품은 하나도 빠짐없이 대답해줘야합니다.\n",
    "\n",
    "    {context}\"\"\"\n",
    ")\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(openai, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시도\n",
    "documents_rag_chain = RetrievalQA.from_chain_type(\n",
    "    retriever=retriever,\n",
    "    llm = openai,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"2023년도에 나온 제품들 중 단종된 제품 이름을 전부 말해줘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm = llm,\n",
    "                                 chain_type= \"stuff\",\n",
    "                                 retriever = docsearch.as_retriever(\n",
    "                                     search_type=\"mmr\",\n",
    "                                     search_kwargs={'k':1, 'fetch_k': 5}),\n",
    "                                     return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa(user_query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"2023년도에 나온 제품들 중 단종된 제품 이름을 전부 말해줘\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    "    return_source_documents=True,\n",
    ")[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
