{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chains import ConversationChain, LLMChain, LLMRouterChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xionic-ko-llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"http://sionic.chat:8001/v1\",\n",
    "    api_key = \"934c4bbc-c384-4bea-af82-1450d7f8128d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='cmpl-b68b656c7fa0488f933e78d9c9bf89b9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"아이브 리더인 안유진은 데뷔 전 걸그룹 IZ*ONE에서 활동했습니다. IZ*ONE은 2018년 Mnet에서 방영된 리얼리티 프로그램 '프로듀스 48'을 통해 결성된 프로젝트 걸그룹으로, 2018년 10월 29일 데뷔 했습니다. 이 그룹은 프로듀스 48에 참가한 96명의 연습생 중 최종 12명을 선발하여 구성됐으며, 안유진은 이 중 한 명으로 선발됐습니다. IZ*ONE은 2021년 4월 29일까지 활동했으며, 이후 안유진은 아이브의 리더로 데뷔하게 됩니다.\", role='assistant', function_call=None, tool_calls=None), stop_reason=None)], created=1721259565, model='xionic-ko-llama-3-70b', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=166, prompt_tokens=56, total_tokens=222))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"xionic-ko-llama-3-70b\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant. You will be given a task. You must generate a detailed and long answer in korean.\"},\n",
    "        {\"role\": \"user\", \"content\": \"아이브 리더가 활동했던 이전 걸그룹의 명칭은?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문서 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Users/SUNJIN/Documents/인턴/03_ideachatbot/data\"\n",
    "Product_data = os.path.join(\n",
    "    PATH, \"년도별 신제품 리스트_냉장-240425.xlsx\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt_template(file_path: str) -> str:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        prompt_template = f.read()\n",
    "\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_chain(template_path):\n",
    "#     prompt_template = read_prompt_template(template_path)\n",
    "    \n",
    "#     chain = LLMChain(\n",
    "#         llm=\"xionic-ko-llama-3-70b\",\n",
    "#         prompt=ChatPromptTemplate.from_template(template=prompt_template),\n",
    "#         max_tokens=150,\n",
    "#         temperature=0.7,\n",
    "#         stop=None\n",
    "#     )\n",
    "    \n",
    "#     return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(llm, template_path, output_key):\n",
    "    return LLMChain(\n",
    "        llm = llm,\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            template=read_prompt_template(template_path)\n",
    "        ),\n",
    "        output_key=output_key,\n",
    "        verbose=True,        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data = create_chain(\n",
    "    llm = llm\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
